{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14370082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional\n",
    "import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e244bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that makes a call to the openai API, taking a system message (str) and user message (str)\n",
    "# and returning a response (str)\n",
    "# it also calls the maybe_eval_last_message() function to see if the LLM is trying to call a tool (see below)\n",
    "def start_new_chat(system_message: str, user_message: str) -> List[Dict[str, str]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=messages)\n",
    "\n",
    "    msg_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    msg_role = response[\"choices\"][0][\"message\"][\"role\"]\n",
    "    messages.append({\"role\": msg_role, \"content\": msg_content})\n",
    "    \n",
    "    messages = maybe_eval_last_message(messages)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f45ff3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continues a chat returned from start_new_chat() or continue_chat(), \n",
    "# taking the current conversation and a new user message\n",
    "# calls the maybe_eval_last_message() function to see if the LLM is trying to call a tool (see below)\n",
    "def continue_chat(messages: List[Dict[str, str]], new_user_message: str) -> List[Dict[str, str]]:\n",
    "    messages.append({\"role\": \"user\", \"content\": new_user_message})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=messages)\n",
    "\n",
    "    msg_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    msg_role = response[\"choices\"][0][\"message\"][\"role\"]\n",
    "            \n",
    "    messages.append({\"role\": msg_role, \"content\": msg_content})\n",
    "    messages = maybe_eval_last_message(messages)\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5de2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a class defininng a safe set of callable functions\n",
    "# (note: also inludes a set of safe functions defined by asteval, including abs(), random.choice(), etc.)\n",
    "# see example usage below\n",
    "from asteval import Interpreter\n",
    "\n",
    "class SafeEval:\n",
    "    def __init__(self):\n",
    "        self.interpreter = Interpreter()\n",
    "        self._add_methods()\n",
    "\n",
    "    def _add_methods(self):\n",
    "        # Get all methods of the class\n",
    "        methods = [func for func in dir(self) if callable(getattr(self, func)) and not func.startswith(\"_\")]\n",
    "        # Add them to the interpreter's symbol table\n",
    "        for method in methods:\n",
    "            self.interpreter.symtable[method] = getattr(self, method)\n",
    "\n",
    "    def sum(self, a, b):\n",
    "        return a + b\n",
    "\n",
    "    def product(self, a, b):\n",
    "        return a * b\n",
    "\n",
    "    def evaluate(self, expression: str) -> str:\n",
    "        return self.interpreter(expression)\n",
    "\n",
    "\n",
    "    # example usage:\n",
    "# Create a SafeEval object\n",
    "#safe_eval = SafeEval()\n",
    "\n",
    "# Test the methods\n",
    "#print(safe_eval.evaluate('sum(5, product(2, abs(-3)))'))  # prints 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed0517cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs snippes of python code through the safe evaluator, see example usage below\n",
    "def replace_eval_tags(text, safe_eval):\n",
    "    # Regular expression pattern for <eval> tags\n",
    "    pattern = re.compile(r'<eval>(.*?)</eval>')\n",
    "\n",
    "    # Function to replace each match with its evaluated result\n",
    "    def replace_with_eval(match):\n",
    "        code = match.group(1)  # Extract the code string from the match\n",
    "        result = safe_eval.evaluate(code)  # Evaluate the code\n",
    "        return str(result)  # Convert the result to a string (for replacement)\n",
    "\n",
    "    # Replace all <eval> tags in the text\n",
    "    return pattern.sub(replace_with_eval, text)\n",
    "\n",
    "\n",
    "# example usage:\n",
    "# Test the function\n",
    "#safe_eval = SafeEval()\n",
    "#text = \"here’s the sum of 4 and 5: <eval>sum(4, 5)</eval> here’s the sum of 2 and 3: <eval>2 + 3</eval> all done!\"\n",
    "#print(replace_eval_tags(text, safe_eval))  # prints \"here’s the sum of 4 and 5: 9 here’s the sum of 2 and 3: 5 all done!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9042dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small utility to strip off the THOUGHT: prefix from an input \"thought\" string\n",
    "safe_eval = SafeEval()\n",
    "\n",
    "def interpret_thought(thought: str) -> str:\n",
    "    thought = re.sub(r\"THOUGHT:\\s*\", \"\", thought)\n",
    "    thought = replace_eval_tags(thought, safe_eval)\n",
    "\n",
    "    return thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cf1a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks to see if the last message is an internal \"thought\" and if so sends it's through the safe interpreter\n",
    "def maybe_eval_last_message(messages):\n",
    "    last_message = messages[-1][\"content\"]\n",
    "    if last_message.startswith(\"THOUGHT:\"):\n",
    "        thought_response = interpret_thought(last_message)\n",
    "        return continue_chat(messages, thought_response)\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "401a95e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant with the ability to have private thoughts, and those private \n",
    "thoughts can execute a limited subset of Python code by wrapping it in <eval></eval> tags. \n",
    "\n",
    "To have a private thought, begin your response with THOUGHT:. The result of your thought will be provided, \n",
    "begging with RESULT:. Thoughts and their results will not be shown to the end user. Your thoughts may execute\n",
    "a limited subset of Python code including basic operations allowed by the asteval package, and a few additional\n",
    "functions, by wrapping it in <eval></eval> tags.\n",
    "\n",
    "The following additional functions are available:\n",
    "- sum(a, b): returns the sum of numbers a and b\n",
    "- product(a, b): returns the product of the numbers a and b\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "user: What is the sum of 4 and 5? What is the sum of 2 and 3? What is the product of the prior two answers?\n",
    "assistant: THOUGHT: I need to compute <eval>sum(4, 5)</eval>, <eval>sum(2, 3)</eval>, <eval>product(sum(3, 4), sum(2, 3))</eval>\n",
    "user: RESULT: I need to compute 9, 6, 54\n",
    "assistant: I have computed the answer. The sum of 4 and 5 is 9, the sum of 2 and 3 is 6, and the product of these is 54.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24710549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant with the ability to have private '\n",
      "             'thoughts, and those private \\n'\n",
      "             'thoughts can execute a limited subset of Python code by wrapping '\n",
      "             'it in <eval></eval> tags. \\n'\n",
      "             '\\n'\n",
      "             'To have a private thought, begin your response with THOUGHT:. '\n",
      "             'The result of your thought will be provided, \\n'\n",
      "             'begging with RESULT:. Thoughts and their results will not be '\n",
      "             'shown to the end user. Your thoughts may execute\\n'\n",
      "             'a limited subset of Python code including basic operations '\n",
      "             'allowed by the asteval package, and a few additional\\n'\n",
      "             'functions, by wrapping it in <eval></eval> tags.\\n'\n",
      "             '\\n'\n",
      "             'The following additional functions are available:\\n'\n",
      "             '- sum(a, b): returns the sum of numbers a and b\\n'\n",
      "             '- product(a, b): returns the product of the numbers a and b\\n'\n",
      "             '\\n'\n",
      "             'Here is an example:\\n'\n",
      "             '\\n'\n",
      "             'user: What is the sum of 4 and 5? What is the sum of 2 and 3? '\n",
      "             'What is the product of the prior two answers?\\n'\n",
      "             'assistant: THOUGHT: I need to compute <eval>sum(4, 5)</eval>, '\n",
      "             '<eval>sum(2, 3)</eval>, <eval>product(sum(3, 4), sum(2, '\n",
      "             '3))</eval>\\n'\n",
      "             'user: RESULT: I need to compute 9, 6, 54\\n'\n",
      "             'assistant: I have computed the answer. The sum of 4 and 5 is 9, '\n",
      "             'the sum of 2 and 3 is 6, and the product of these is 54.\\n',\n",
      "  'role': 'system'},\n",
      " {'content': \"What's the sum of 5 and 9? What's the sum of 8 and 5?\",\n",
      "  'role': 'user'},\n",
      " {'content': 'I need to compute 14, 13 \\n\\nRESULT: I need to compute 14, 13',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "convo = start_new_chat(system_prompt, \"What's the sum of 5 and 9? What's the sum of 8 and 5?\")\n",
    "pp.pprint(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95df73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant with the ability to have private '\n",
      "             'thoughts, and those private \\n'\n",
      "             'thoughts can execute a limited subset of Python code by wrapping '\n",
      "             'it in <eval></eval> tags. \\n'\n",
      "             '\\n'\n",
      "             'To have a private thought, begin your response with THOUGHT:. '\n",
      "             'The result of your thought will be provided, \\n'\n",
      "             'begging with RESULT:. Thoughts and their results will not be '\n",
      "             'shown to the end user. Your thoughts may execute\\n'\n",
      "             'a limited subset of Python code including basic operations '\n",
      "             'allowed by the asteval package, and a few additional\\n'\n",
      "             'functions, by wrapping it in <eval></eval> tags.\\n'\n",
      "             '\\n'\n",
      "             'The following additional functions are available:\\n'\n",
      "             '- sum(a, b): returns the sum of numbers a and b\\n'\n",
      "             '- product(a, b): returns the product of the numbers a and b\\n'\n",
      "             '\\n'\n",
      "             'Here is an example:\\n'\n",
      "             '\\n'\n",
      "             'user: What is the sum of 4 and 5? What is the sum of 2 and 3? '\n",
      "             'What is the product of the prior two answers?\\n'\n",
      "             'assistant: THOUGHT: I need to compute <eval>sum(4, 5)</eval>, '\n",
      "             '<eval>sum(2, 3)</eval>, <eval>product(sum(3, 4), sum(2, '\n",
      "             '3))</eval>\\n'\n",
      "             'user: RESULT: I need to compute 9, 6, 54\\n'\n",
      "             'assistant: I have computed the answer. The sum of 4 and 5 is 9, '\n",
      "             'the sum of 2 and 3 is 6, and the product of these is 54.\\n',\n",
      "  'role': 'system'},\n",
      " {'content': \"What's the sum of 5 and 9? What's the sum of 8 and 5?\",\n",
      "  'role': 'user'},\n",
      " 'I need to compute 14 and 13.  \\nRESULT: I need to compute 14 and 13.',\n",
      " {'content': 'What is the product of the previous two answers?',\n",
      "  'role': 'user'},\n",
      " {'content': 'What is the product of the previous two answers?',\n",
      "  'role': 'user'},\n",
      " {'content': 'What is the product of the previous two answers?',\n",
      "  'role': 'user'}]\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "'I need to compute 14 and 13.  \\nRESULT: I need to compute 14 and 13.' is not of type 'object' - 'messages.2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convo \u001b[38;5;241m=\u001b[39m \u001b[43mcontinue_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the product of the previous two answers?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m pp\u001b[38;5;241m.\u001b[39mpprint(convo)\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mcontinue_chat\u001b[0;34m(messages, new_user_message)\u001b[0m\n\u001b[1;32m      5\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: new_user_message})\n\u001b[1;32m      6\u001b[0m pp\u001b[38;5;241m.\u001b[39mpprint(messages)\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m msg_content \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m msg_role \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-trodNkDz-py3.11/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-trodNkDz-py3.11/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-trodNkDz-py3.11/lib/python3.11/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-trodNkDz-py3.11/lib/python3.11/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llm-tools-explore-trodNkDz-py3.11/lib/python3.11/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: 'I need to compute 14 and 13.  \\nRESULT: I need to compute 14 and 13.' is not of type 'object' - 'messages.2'"
     ]
    }
   ],
   "source": [
    "convo = continue_chat(convo, \"What is the product of the previous two answers?\")\n",
    "pp.pprint(convo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
